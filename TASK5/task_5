import nltk
from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer, WordNetLemmatizer

text=input("Enter a paragraph of text: ")
text

tokens=word_tokenize(text.lower())
tokens

#Stop-word
stop_words=set(stopwords.words('english'))
op1=[word for word in tokens if word not in stop_words]
print(op1)

#Stemming
stemming=PorterStemmer()
op2=[stemming.stem(word) for word in op1]
print(op2)

#Lemmeatization
lemm=WordNetLemmatizer()
op3=[lemm.lemmatize(word) for word in op1]
print(op3)

import numpy as np
def load_glove_embeddings(file_path):
    embeddings_index = {}
    with open(file_path, encoding="utf-8") as f:
        for line in f:
            values = line.split()
            word = values[0]
            vector = np.asarray(values[1:], dtype='float32')
            embeddings_index[word] = vector
    return embeddings_index

glove = 'file-path\glove.6B.300d.txt'
glove_embeddings = load_glove_embeddings(glove)
glove_embeddings

input_word = input("Enter a word: ").strip().lower()

if input_word in glove_embeddings:
    word_vector = glove_embeddings[input_word]
    print('GloVe Vector for {}'.format(input_word))
    print(word_vector)
else:
    print("Word {} not found in GloVe embeddings.".formart(input_word))

# Find most similar words (cosine similarity)
def find_most_similar(word, embeddings, top_n=5):
    if word not in embeddings:
        return []
    word_vec = embeddings[word]
    similarities = {}
    for other_word, other_vec in embeddings.items():
        if other_word == word:
            continue
        similarity = np.dot(word_vec, other_vec) / (np.linalg.norm(word_vec) * np.linalg.norm(other_vec))
        similarities[other_word] = similarity
    sorted_similarities = sorted(similarities.items(), key=lambda item: item[1], reverse=True)
    return sorted_similarities[:top_n]


similar_words = find_most_similar(input_word, glove_embeddings)
print("\nMost Similar Words to {}:".format(input_word))
for similar_word, similarity in similar_words:
    print(f"{similar_word}: {similarity}")
